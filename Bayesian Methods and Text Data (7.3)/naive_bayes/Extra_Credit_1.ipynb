{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Classification with Naive Bayes\n",
    "### extra credit part 1\n",
    "***\n",
    "In the mini-project, you'll learn the basics of text analysis using a subset of movie reviews from the rotten tomatoes database. You'll also use a fundamental technique in Bayesian inference, called Naive Bayes. This mini-project is based on [Lab 10 of Harvard's CS109](https://github.com/cs109/2015lab10) class.  Please free to go to the original lab for additional exercises and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 15561\n",
      "Number of critics: 623\n",
      "Number of movies:  1921\n",
      "Number of bigrams: 147225\n",
      "Practice assessing the dictionary...\n",
      "The 2000th bigram: action delivers\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six.moves import range\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup Pandas\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "critics = pd.read_csv('./critics.csv')\n",
    "critics = critics[~critics.quote.isnull()] #drop rows with missing quotes\n",
    "critics.head()\n",
    "\n",
    "n_reviews = len(critics)\n",
    "n_movies = critics.rtid.unique().size\n",
    "n_critics = critics.critic.unique().size\n",
    "\n",
    "print(\"Number of reviews: {:d}\".format(n_reviews))\n",
    "print(\"Number of critics: {:d}\".format(n_critics))\n",
    "print(\"Number of movies:  {:d}\".format(n_movies))\n",
    "\n",
    "texts = critics.quote\n",
    "\n",
    "# practice CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                            ngram_range = (1, 2))\n",
    "\n",
    "vectorizer.fit_transform(texts)\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "print('Number of bigrams: ' + str(len(vocab.items())))\n",
    "print('Practice assessing the dictionary...')\n",
    "w2000 = [w for w in vocab.items() if w[1] == 2000]\n",
    "print('The 2000th bigram: ' + w2000[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful functions from Springboard's assignment \n",
    "\n",
    "def cv_score(clf, X, y, scorefunc):\n",
    "    # compute average accuracy from KFold \n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average\n",
    "\n",
    "def log_likelihood(clf, x, y):\n",
    "    # compute log_likelihood value\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    rotten = y == 0\n",
    "    fresh = ~rotten\n",
    "    return prob[rotten, 0].sum() + prob[fresh, 1].sum()\n",
    "\n",
    "# split into train and test set\n",
    "_, itest = train_test_split(range(critics.shape[0]), train_size=0.7,\n",
    "                           random_state = 0)\n",
    "mask = np.zeros(critics.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Springboard assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Previously, we had accuracy around 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement:\n",
    "1. Add ngram: ngram_range = (1, 2)\n",
    "2. Remove stop words \n",
    "3. chi-squared feature selection\n",
    "4. Try TF-IDF and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutinomial NB with TF-IDF\n",
      "----------------------------------------\n",
      "Optimal alpha = 0.001\n",
      "Optimal K = 6500\n",
      "----------------------------------------\n",
      "Accuracy on training data: 0.919469\n",
      "Accuracy on test data:     0.786173\n",
      "----------------------------------------\n",
      "[[2233 2015]\n",
      " [ 314 6330]]\n"
     ]
    }
   ],
   "source": [
    "# Mutinomial NB with TF-IDF\n",
    "\n",
    "# Tuning hyper paramaters:\n",
    "# (1) alpha = Multinomial NB additive smoothing parameter\n",
    "# (2) K = Select features according to the K highest scores.\n",
    "\n",
    "# define grid to look for\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "Ks = [4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000]\n",
    "\n",
    "best_alpha = None\n",
    "best_K = None\n",
    "maxscore = -np.inf\n",
    "\n",
    "# grid search\n",
    "for alpha in alphas:\n",
    "    for K in Ks: \n",
    "        \n",
    "        vectorizer = TfidfVectorizer(stop_words = 'english',\n",
    "                                     ngram_range = (1, 2))\n",
    "        \n",
    "        X_all = vectorizer.fit_transform(critics.quote)\n",
    "        X_all = X_all.tocsc()\n",
    "        y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        # x_all uses all avilable features (words)\n",
    "        \n",
    "        # chi-squared feature selection: x_new contains selected words \n",
    "        X_new = SelectKBest(chi2, k=K).fit_transform(X_all, y_all)\n",
    "\n",
    "        Xtrainthis = X_new[mask] #define training set\n",
    "        ytrainthis = y_all[mask]\n",
    "\n",
    "        clf = MultinomialNB(alpha=alpha) # classifier\n",
    "        \n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha = alpha\n",
    "            best_K = K\n",
    "\n",
    "# fitting the test set \n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english',\n",
    "                             ngram_range = (1, 2))\n",
    "\n",
    "X_all = vectorizer.fit_transform(critics.quote)\n",
    "X_all = X_all.tocsc()\n",
    "y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        \n",
    "X_new = SelectKBest(chi2, k = best_K).fit_transform(X_all, y_all)\n",
    "\n",
    "Xtrain = X_new[mask] # training set\n",
    "ytrain = y_all[mask]\n",
    "Xtest = X_new[~mask] # test set\n",
    "ytest = y_all[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(Xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "print(\"Mutinomial NB with TF-IDF\")\n",
    "print(\"----------------------------------------\")\n",
    "print('Optimal alpha = ' + str(best_alpha))\n",
    "print('Optimal K = ' + str(best_K))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"----------------------------------------\")\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutinomial NB with CountVectorizer\n",
      "----------------------------------------\n",
      "Optimal alpha = 0.5\n",
      "Optimal K = 5000\n",
      "----------------------------------------\n",
      "Accuracy on training data: 0.899336\n",
      "Accuracy on test data:     0.814818\n",
      "----------------------------------------\n",
      "[[2806 1442]\n",
      " [ 575 6069]]\n"
     ]
    }
   ],
   "source": [
    "# Mutinomial NB with CountVectorizer\n",
    "\n",
    "# Tuning hyper paramaters:\n",
    "# (1) alpha = Multinomial NB additive smoothing parameter\n",
    "# (2) K = Select features according to the K highest scores.\n",
    "\n",
    "# define grid to look for\n",
    "alphas = [0.01, 0.1, 0.25, 0.5, 0.75, 1, 1.5]\n",
    "Ks = [4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000]\n",
    "\n",
    "best_alpha = None\n",
    "best_K = None\n",
    "maxscore = -np.inf\n",
    "\n",
    "for alpha in alphas:\n",
    "    for K in Ks: \n",
    "        \n",
    "        vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                                     ngram_range = (1, 2))\n",
    "        \n",
    "        X_all = vectorizer.fit_transform(critics.quote)\n",
    "        X_all = X_all.tocsc()\n",
    "        y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        \n",
    "        X_new = SelectKBest(chi2, k=K).fit_transform(X_all, y_all)\n",
    "\n",
    "        Xtrainthis = X_new[mask]\n",
    "        ytrainthis = y_all[mask]\n",
    "\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        \n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha = alpha\n",
    "            best_K = K\n",
    "\n",
    "# fitting the test set \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                             ngram_range = (1, 2))\n",
    "\n",
    "X_all = vectorizer.fit_transform(critics.quote)\n",
    "X_all = X_all.tocsc()\n",
    "y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        \n",
    "X_new = SelectKBest(chi2, k = best_K).fit_transform(X_all, y_all)\n",
    "\n",
    "Xtrain = X_new[mask]\n",
    "ytrain = y_all[mask]\n",
    "Xtest = X_new[~mask]\n",
    "ytest = y_all[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(Xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "print(\"Mutinomial NB with CountVectorizer\")\n",
    "print(\"----------------------------------------\")\n",
    "print('Optimal alpha = ' + str(best_alpha))\n",
    "print('Optimal K = ' + str(best_K))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"----------------------------------------\")\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:628: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with CountVectorizer\n",
      "----------------------------------------\n",
      "Optimal max_depth = 1000\n",
      "Optimal K = 6000\n",
      "----------------------------------------\n",
      "Accuracy on training data: 0.982652\n",
      "Accuracy on test data:     0.707033\n",
      "----------------------------------------\n",
      "[[1826 2422]\n",
      " [ 769 5875]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with CountVectorizer\n",
    "\n",
    "list_max_depth = [50,100,300,500,1000]\n",
    "Ks = [4000, 4500, 5000, 5500, 6000]\n",
    "\n",
    "best_max_depth = None\n",
    "best_K = None\n",
    "maxscore = -np.inf\n",
    "\n",
    "for max_depth in list_max_depth:\n",
    "    for K in Ks: \n",
    "        \n",
    "        vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                                     ngram_range = (1, 2))\n",
    "        \n",
    "        X_all = vectorizer.fit_transform(critics.quote)\n",
    "        X_all = X_all.tocsc()\n",
    "        y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        \n",
    "        X_new = SelectKBest(chi2, k=K).fit_transform(X_all, y_all)\n",
    "\n",
    "        Xtrainthis = X_new[mask]\n",
    "        ytrainthis = y_all[mask]\n",
    "\n",
    "        clf = RandomForestClassifier(max_depth = max_depth,\n",
    "                                     n_estimators = 100)\n",
    "        \n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            best_max_depth = max_depth\n",
    "            best_K = K\n",
    "\n",
    "# fitting the test set \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                             ngram_range = (1, 2))\n",
    "\n",
    "X_all = vectorizer.fit_transform(critics.quote)\n",
    "X_all = X_all.tocsc()\n",
    "y_all = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "        \n",
    "X_new = SelectKBest(chi2, k = best_K).fit_transform(X_all, y_all)\n",
    "\n",
    "Xtrain = X_new[mask]\n",
    "ytrain = y_all[mask]\n",
    "Xtest = X_new[~mask]\n",
    "ytest = y_all[~mask]\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = best_max_depth,\n",
    "                             n_estimators = 100).fit(Xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "print(\"Random Forest with CountVectorizer\")\n",
    "print(\"----------------------------------------\")\n",
    "print('Optimal max_depth = ' + str(max_depth))\n",
    "print('Optimal K = ' + str(best_K))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"----------------------------------------\")\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "From the Springboard assignment, I made an improvement as follows:\n",
    "\n",
    "1. Use Mutinomial NB\n",
    "2. Use CountVectorizer\n",
    "3. Remove stop words\n",
    "4. Use bigrams\n",
    "5. Use chi-squared feature selection\n",
    "\n",
    "The accuracy increases from 0.72 to 0.81"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
